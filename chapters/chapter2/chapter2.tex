\chapter{Security Review of Containers}\label{chapter2}	

In spite of the popularity of containers, there are various security
concerns as well. Here, we focus our investigation on the security
of Singularity and Docker containers because of three reasons.
First, they are popular among containers.
Second, security becomes a barrier in the adoption of containers in
production. Third, both are already
used in various environments, so it is easy to practically
investigate their security. In this chapter, we study a set of security
requirements, that each OS-level virtualization solution should provide.
Additionally, this chapter investigates how these requirements are fulfilled
by Singularity and Docker containers, and list their security implications.
For this study, we categorize security into two broad categories: internal
security provided by containers, and external security
provided by the Linux operating system.

\section{Container's Internal Security}

We examine the security of containers based on the requirements given
by Reshetova et al., 2014 \cite{reshetova2014security} for comparing
the security of a number of OS-level virtualization techniques.
According to this research, an OS-level virtualization technique should
satisfy the following requirements: process isolation, filesystem isolation,
device isolation, IPC isolation, network isolation and limiting
of resources inside containers. Apart from that, in this section, we provide vulnerabilities
that are added to containers by container images ~\cite{cappos2008look, gummaraju2015over}.

\subsection{Process Isolation}

The main goal of process isolation is to prevent one container process
from seeing or interfering with another container process. In other words,
it limits the permissions and visibility of a container process to
processes running in other containers. Containers achieve this goal
through the use of namespaces in the Linux kernel. For this purpose,
Docker uses \textit{PID namespaces} which isolate a process with a
particular process ID from the host and other containers. Provided
that, it becomes difficult for an attacker to see processes running
in other containers, hence harder to attack them \cite{bui2015analysis}.
In contrast to Docker, the default configuration of Singularity does
not isolate PID namespaces of containers from the host.
The reason behind that is Singularity's main goal is to provide
mobility of compute and reproducibility, and not full isolation.
However, this configuration can be changed to separate the \textit{PID}
namespaces either by using a command line or environment variable setting.

\subsection{Filesystem Isolation}

Filesystem isolation is required to prevent illegitimate access
to filesystems of the host and containers. Docker uses
\textit{filesystem namespaces}, also called \textit{mount namespaces},
for achieving this goal. Filesystem namespaces hide filesystems of
the host and containers from other containers. However, some of the
kernel filesystems are not namespaced, so Docker containers mount
them for operation. For example, \textit{/sys, /proc/sys,
/proc/sysrq - trigger, /proc/irq, and /proc/bus} are
not namespaced~\cite{walsh}.
This causes security concerns as Docker containers are directly
able to access host filesystems. Consequently, Docker provides
two filesystem protection mechanisms. First, Docker gives
read-only permissions to containers for these filesystems. Second,
containers are not allowed to remount any filesystem within containers.
Additionally, Docker offers a \textit{copy-on-write} filesystem mechanism,
which allows containers to write to their specific filesystems and changes
are not visible to other containers.
Similarly, files in Singularity containers are also isolated using
\textit{filesystem} namespaces.

\subsection{Device Isolation}

Applications and kernel access devices through special files
known as device nodes. It is very crucial to limit the set
of devices nodes that containers can access. This is primarily
because an attacker can own the whole system by gaining access
to some important device nodes such as /dev/mem, /dev/sd*,
or /dev/tty. Docker uses the \textit{Device Whitelist Controller}
\cite{whitelistController} feature of control groups to limit the
set of devices that a Docker container can see and use.
Additionally, Docker starts containers with \textit{nodev} which
prevents the use of already created device nodes inside the image.
Furthermore, Docker does not allow containers to create new device
nodes. However, some of the important device nodes cannot be
namespaced such as \textit{/dev/mem, /dev/sd*}, and kernel modules.
Direct access to these device nodes by containers possess serious
security concerns. Besides that, if a Docker container is executed
in \textit{privileged} mode then it gets access to all devices.
Conversely, in default configuration of Singularity, all host devices
are visible inside the container because the user is same inside and
outside the container.


\subsection{Inter-Process Communication (IPC) Isolation}

IPC is a set of objects through which processes communicate with
each other, such as shared memory segments, semaphores, and message queues.
IPC isolation is needed to prevent containers
from accessing or modifying data belonging to other containers, which is
transmitted through these objects. Docker utilizes \textit{IPC namespaces}
to assign an IPC namespace to each container. Process in one IPC namespace
cannot read or write IPC resources of another IPC namespace.
The default configuration of Singularity does not provide IPC isolation.

\subsection{Network Isolation}


Isolation of container's network is very important to prevent
network-based attacks such as address resolution protocol (ARP)
spoofing and Man-in-the-Middle (MitM) Attack \cite{lockhart2004network}.
ARP spoofing is an attack which associates the attacker's Media Access
Control (MAC) address with the Internet Protocol (IP) address of another host.
ARP is a stateless protocol, hence hosts save all ARP replies even if they had not
sent any ARP request for it \cite{ramachandran2005detecting}, which becomes a
source of attack. So, the host that has spoofed ARP response is not able to
verify whether it belongs to legitimate host or attacker, and hence it starts
sending packets at attacker's MAC address.
In Singularity, by default, the container shares the network with the host.
This is because Singularity tries to virtualize "as few as possible" namespaces.
Whereas, Docker uses \textit{network} namespaces
\cite{NetworkNamespace} to isolate the network of Docker containers.
Therefore, each Docker container has its different IP address,
IP routing tables, network devices, etc. Consequently, Docker containers
interact through the network interfaces with each other as well as with
the host \cite{dockerNetworkdoc}. On the contrary, all containers share
the same network bridge, which makes Docker vulnerable to ARP spoofing attack.
In addition to that, bridge of Docker network forwards all incoming packets
without any kind of filtering, which makes it vulnerable to Mac flooding
\cite{bui2015analysis}.
In Docker, the network is used for two purposes : (\rom{1}) to control
Docker daemon remotely, (\rom{2}) to distribute images, which
include pulling and saving images on Docker Hub.

\subsubsection{Docker Daemon Remote Control}

Docker daemon is controlled remotely through a socket (which
is by default a Unix socket but can be changed to TCP socket),
so Docker commands can be performed from another host
remotely \cite{combe2016docker}. By accessing this socket,
an attacker can pull and run containers in privileged mode,
hence getting root access to the host.

\subsubsection{Vulnerable Image Distribution Process}

Docker images are present in compressed format on Docker Hub.
So, Docker daemon pulls, uncompresses, and then runs containers
from these images. Here, Docker daemon can be related to the
package manager and Docker Hub to the software repository.
Hence, Docker daemon also has an attack surface similar
to the package manager. Vulnerabilities include storing,
processing potentially untrusted code in Docker images by
Docker daemon. The source code can be tampered during transfer
or at the source. If some part of the network is compromised,
an attacker can replace an image with malicious image, and
that image gets downloaded on the host. As the image is in
a compressed format, the attacker can cleverly craft the
image (i.e. all zeros). If so, it has the potential of
filling whole storage on the host after decompression,
hence causing
denial-of-service (DoS) attack. Other possible attacks are
code injection or replay attacks. Additionally, the malicious
image can be uploaded to the Docker Hub by an adversary.
That image can be downloaded by millions of users infecting
millions of machines.

For mitigation of these attacks, Docker introduced content
trust which allows signing images before pushing to Docker
Hub. However, this content trust can be disabled and thus disabling
image signature check. Another issue is related to automated build and
webhooks, where compromised GitHub
account can lead to the execution of a malicious code. According
to the experiment performed in \cite{martin2018docker} the
malicious code was put in production in a very short time i.e within 5 minutes and
30 seconds of commit on GitHub. The content trust provides
an environment where a single entity is trusted but in this
case, trust is divided among several external entities.


\subsection{Limiting of Resources}

A DoS attack occurs when intended users are not able to use
the system or network resources \cite{us-cert}. To launch DoS,
the attacker floods targeted host or network traffic with
superfluous requests to overload systems. Consequently,
the target crashes or its resources get exhausted,
hence disrupting normal execution of the
system. To solve this issue, both Docker and Singularity use \textit{cgroups}.
Cgroups restrict the amount of resources (CPU, memory,
and disk I/O) that are used by containers, thus not
allowing one container to consume all resources.

\subsection{Vulnerabilities in Container Images}

There can be vulnerabilities present inside the image
itself when it is downloaded from the image repository.
According to~\cite{Shu2017} over
30\% official Docker images had high-priority common vulnerabilities
and exposures (CVE) identifiers (IDs) and around 64\% had high
or medium level CVE vulnerabilities at the time of this work.
This research work also
states that Docker images with the \textit{latest} tag also had
vulnerabilities. These vulnerabilities are due to outdated
packages contained in images, which may be a consequence of
the use of old base image or due to
pulling of outdated code during build.

Docker introduced Docker security scanning through which users
can scan images to check whether they contain vulnerability or not.
However, this scanning is limited to only private repositories and
it is a paid service. The scan traverses all layers of the image and
then identifies software packages in those layers. Further, it
checks vulnerabilities in these software components by taking
their Secure Hash Algorithms (SHAs) and then comparing against a
standard list of CVEs. This scan can take up to 24 hours
depending on image sizes. Additionally, this scanning technique
does not detect malware, virus, or vulnerabilities which are not mentioned in the standard
CVE database \cite{dockerdoc_2018}.

\section{Security provided by Kernel}

Out-of-the-box security provided by the Linux kernel, which secures the
host from containers, is known as host hardening.
Linux provides Linux capabilities and Linux Security Modules (LSM)
to harden the security of the host system. Linux capabilities divide
the privileges of superuser into pieces, and assign a subset of these
capabilities to specific processes. Whereas, LSM provides a framework
for Linux to support various security modules. Currently, three security
modules are officially integrated with Linux kernel which includes SELinux,
AppArmor, and Seccomp. Out of these three, only the first two are
supported by Docker. Docker only integrates with Seccomp if LXC are used.
Below, we provide the details of these host hardening techniques.

\subsection{Linux Capabilities}

According to the official documentation of Linux~\cite{man7},
Unix systems traditionally categorized processes as \textit{privileged} processes and
\textit{unprivileged} processes. Privileged processes are root users with
zero user id (UID), whereas unprivileged users are normal users with nonzero
UID. Privileged processes are exempted from permission check, whereas
unprivileged processes are liable to full permission checks.
Linux divides privileges of superuser into different pieces, known as
capabilities, which can be independently enabled or disabled.
As a result, Docker can disable some of the capabilities of containers,
thus improving the security of the system. As Docker containers share the
kernel with the host, most of their tasks are done by the host. As a
consequence, disabling some of the capabilities in Docker containers do
not affect their functionality. For example, \textit{CAP\_NET\_ADMIN}
capability allows configuration of the network, which can be disabled in
Docker containers because all network configurations are handled by
Docker daemon. By default, most of Linux capabilities are disabled
when Docker container is started in order to secure the host system
from attackers \cite{walsh2}. Table \ref{tab:capabilities} lists some of the
capabilities that are disabled in Docker containers.

\begin{center}
\tabulinesep=1.2mm
\begin{tabu} to \textwidth { | X[l] | X[l] | }
\hline
 CAP\_SETPCAP & Modify process capabilities \\
 \hline
CAP\_SYS\_MODULE & Insert/Remove kernel modules \\
 \hline
CAP\_SYS\_RAWIO & Modify kernel memory \\
 \hline
CAP\_SYS\_PACCT & Configure process accounting \\
 \hline
CAP\_SYS\_NICE &  Modify priority of processes \\
 \hline
CAP\_SYS\_RESOURCE & Override resource limits \\
 \hline
CAP\_SYS\_TIME & Modify the system clock \\
 \hline
CAP\_SYS\_TTY\_CONF IG & Configure tty devices \\
 \hline
CAP\_AUDIT\_WRITE & Write the audit log \\
 \hline
CAP\_AUDIT\_CONTROL & Configure audit subsystem \\
 \hline
CAP\_MAC\_OVERRIDE & Ignore kernel MAC policy \\
 \hline
CAP\_MAC\_ADMIN & Configure MAC configuration \\
 \hline
CAP\_SYSLOG & Modify kernel printk behavior \\
 \hline
CAP\_NET\_ADMIN & Configure the network \\
 \hline
CAP\_SYS\_ADMIN & Catch all \\
 \hline
\end{tabu}
\captionof{table}{Some disabled capabilities in Docker containers~\cite{walsh2}.}
\label{tab:capabilities}
\end{center}


\subsection{Linux Security Modules}

Below, we provide details of two LSMs that are currently
supported by Docker.

\subsubsection{SELinux}

SELinux is security enhancement to the Linux system, which
integrates Mandatory Access Control (MAC). MAC strongly separates
all applications, which in turn decreases potential damage if an
application is compromised. SELinux classifies active users or
processes as subjects, and all system resources as objects.
Everything in SELinux is controlled by labels
\cite{smalley2001implementing}. System administrator writes
SELinux policies, which control accesses of system objects
by processes. These policies are of three types: Type
Enforcement (TE), Multi-Category Security (MCS), and Multi-Level
Security (MLS). Out of these three, Docker
uses only the first two types of policies~\cite{bui2015analysis}. Using TE,
Docker protects the host from containers,
by forcing container processes to read/write content
that has a specific label \cite{bui2015analysis}.
MCS is used to protect containers from
other containers. To achieve that, each container is
assigned a unique MCS label. All the files that belong to a
container are also labelled with the same MCS label.
Therefore, kernel does not allow a container process to read/write to a file
that have different MCS label. Hence isolating all containers.

\subsubsection{AppArmor}

Like SELinux, AppArmor is another MAC solution
for enhancing security of Linux systems. It uses
the concept of file system paths instead of labels.
AppArmor mentions the file path in the binary of
the application along with the allowed permissions
on that file. Two modes are supported by AppArmor:
enforcement mode and complain/learning mode~\cite{bui2015analysis}.
Enforcement mode is used to enforce policies that are
defined in the AppArmor profile, whereas complain/learning
mode also allows violations of the profile policies.
However, these violations are logged, and may be used later for
developing new profiles. Docker provides an interface to systems
that support AppArmor. This interface is used to load
AppArmor profile for containers. Consequently, when
containers are launched, a pre-defined AppArmor profile is
loaded automatically, if administrator does not specify
an AppArmor profile. These security profiles are loaded in
enforcement mode by default, to make sure that the policies
defined in the profile are enforced. Therefore, the
important files of the host such as \textit{/sys/fs/cgroups/}
and \textit{/sys/kernel/security/} remain protected from
containers.


\subsubsection{Limitations of LSMs}

Security provided by these modules is limited due to
the generic nature of profiles provided by these security
modules \cite{martin2018docker}. For example, default
SELinux profile assigns same domain to all Docker
containers, which helps in protecting host from containers,
but not containers from containers. Similarly, default
AppArmor profile provide full access of network system and
capabilities to Docker containers.
To improve the security of the host, a potential solution is to write
container-specific profiles.

\subsubsection{Related Work}

The existing research work on containers focuses mainly on the security of containers.
This focus is justified by the fact that containers expose the host's resources
(e.g., file system/ IPC) to the guest system. This feature raises a confidentiality
threat for the applications running on the same host. 

~\cite{reshetova2014security} analyzed security of various OS-level virtualization technologies.
according to a set of security requirements. Based on these requirements, they analyzed
security of FreeBSD Jails, Linux-VServer,
Solaris-Zones, OpenVZ, LxC, and Cells/Cellrox.

Thanh Bui in~\cite{bui2015analysis} used these security requirements to analyze the security of Docker specifically.
The Author selected Docker for analysis due to its popularity as a container-based approach.
In this study, two main areas of security are considered for analysis:
(1) Internal security of Docker, which is analysed according to the
set of security requirements given by Reshtova et. al. in~\cite{reshetova2014security}.
(2) How Docker interacts with the external security features provided
by Linux Kernel such as SELinux and AppArmor.

A study in 2015 by Gummaraju et al.
states that over 30\% of official images in Docker Hub contain high priority
security vulnerabilities~\cite{gummaraju2015over}, whereas this percentage rises 
to ~40\% for community images, which are pushed to Docker Hub by Docker users 
and are not identified by any authority.
At the time of this study, there were ~75 official repositories containing 
~960 unique images and ~95,000 general repositories having hundreds of thousands 
of unique images on Docker Hub.
This study took all official images as well as randomly selected ~1700 general images for analysis.

Combe et al. in~\cite{combe2016docker} and ~\cite{martin2018docker} investigated the security of
Docker ecosystem. In this study, authors primarily reviewed security
from three main factors:

For security it relies on three components i.e 
isolation, host hardening and network security. For isolation 
docker relies on Linux kernel features like namespaces, cgroups, 
hardening and capabilities. The default isolation configuration 
is strict, only flaw is the shared network bridge which is 
vulnerable to ARP attacks between containers on same host. 
There are options for increasing and lowering security levels 
while launching containers and while starting the docker daemon 
which is serious security concern. Host hardening is done by 
loading profiles in containers for e.g SELinux and AppArmor 
profile but the problem is these profiles are generic and protect 
host from containers but not containers from containers. So, writing 
container specific profiles can address this issue. Docker uses network 
to remotely control docker daemon and in the image-distribution process. 
While downloading images from docker hub the connection is made over TLS 
and remote repository is verified with hash. Moreover, starting from version 
1.8 developers can sign images while pushing them to the docker hub using 
timestamps for expiration and preventing replay attacks but the signing keys 
are shared among every entity needing to issue an image which is an issue. 
The docker daemon is remotely controlled through UNIX socket. Access to this 
socket will give attacker the full freedom to pull and run containers in 
privileged mode giving him root access. So, therefore connection should be 
TLS secured.
Authors further discussed three use cases of docker. First is recommended 
use-case given by docker official suggesting micro-service approach. Second 
is wide-spread use where developers use docker as way of delivering virtual 
environment. So, embedding more software than the designed payload of containers 
makes container management very complex and increases attack surfaces. Attacks 
like privilege escalation can happen because of the increased communication 
channels between co-located containers and host. Last one is CaaS (cloud as a 
service). For security, docker swarm uses swarm mode PKI. Each time a new node 
joins swarm, the manager nodes issues certificate to the node.
Authors then discussed two categories of adversary model i.e direct adversary 
targeting production environment directly and indirect adversary who leverages 
docker ecosystem to reach production environment. Authors identified five 
vulnerability categories.

\textbf{Insecure configuration:} Use of options given at the starting of docker daemon 
and while launching of the container makes it insecure. For mitigation of these 
attacks the center for internet security realized a docker benchmark providing 
two list of options to use and not to use while running containers as isolated 
applications.

\textbf{Vulnerabilities in image distribution process:} Vulnerabilities include storing, 
processing potentially untrusted code performed by docker daemon. Code can be 
tampered during transfer or at the source. If attacker compromised some part of 
network, downloading his image on host and it can fill whole storage of host 
causing DoS attack. Other possible attacks are code injection or replay attacks. 
For mitigation of these attacks Docker introduced content trust which allowed 
signing images before pushing to docker hub. But the problem is that this content 
trust can be disabled and thus disabling image signature check. Another issue is 
with automated build and webhooks where compromised github account can lead to the 
execution of malicious code within 5 minutes and 30 seconds. Content trust provides 
environment where single entity is trusted but in this case trust is divided among 
several external entities.

\textbf{Vulnerabilities inside images:} According to the reports 36\% of the official images 
contain high-priority CVE and 64\% official images high to medium priority CVE. Docker 
introduced Docker security scanning which traverses each layer of image and reports 
any vulnerabilities. But this solution is limited to private repositories only due to 
its cost and it can take 1 to 24 hours for the scan.

\textbf{Vulnerabilities directly linked to Docker:} There is room for improvement for security
profiles making them container specific instead of generic profiles giving full access 
to network system, file system of host.

\textbf{Vulnerabilities of Linux kernel:} As containers are sharing kernel with the host, having
root privileges inside the container can make attacker break out of the container and 
attack host.

Shu et al. in~\cite{Shu2017} studied the state of security
vulnerabilities in Docker Hub images.
Authors built DIVA (Docker Image Vulnerability Analysis) framework for analyzing 
the vulnerabilities in the images of docker Hub. This process involved discovering 
the community images, downloading and extracting the meta data and finally analyzing 
the vulnerabilities in the images. The community images were discovered using 
keyboard search. After getting the list of images, they adopted stream based 
parallel image analysis where different subsets of images discovered were 
downloaded on different host and analyzed their vulnerability using Clair, 
which is open source tool from coreOS for identifying vulnerabilities in 
images. From the metadata received after extraction process Clair 
found the insecure packages in the images by comparing with the CVE and similar 
databases. Clair report include details like time of analysis, vulnerability id, 
severity ranking, description of CVE, associated packages and layer id of the 
vulnerable image. Their dataset consisted of total 86,066 repositories out of 
which 98 were official repositories having total of 356,218 images in both 
repositories. With the DIVA framework they found out that there are 180 
vulnerabilities on average in both official and community images. There 
exists at least one type of severe vulnerability in both official and 
community images. 50\% of both official and community images have not 
been updated since last 200 days which are intuitively more likely 
to contain more vulnerabilities.
Then, the authors did the inter-image dependency analysis and found 
that vulnerability propagates from the parent image to the child image. 
Child image inherits 80 or more vulnerabilities on average from parent 
image and child image frequently introduces new vulnerabilities because 
maintainer don’t apply updates while installing new software.  
They generated a directed graph G = <V,E> where V is the set of vertices 
representing layer IDs and E is the set of edges representing child and 
parent relationship. The meta data extraction process gave details like 
image id, image name, last updated time, layer id and commands used to 
build the image. Inter-layer relationships were found from JSON configuration 
file of images. Authors performed metadata extraction using virtual computing 
lab where they reserved 100 virtual machines having 4GB memory and 40GB storage. 
Further, authors found out that 5 out of 98 official repositories and 10,435 out 
of 85,968 community repositories don’t have :latest tag.  From the Clair report 
authors investigated the packages that cause vulnerabilities in images more 
frequently and found that glibc package is the most frequent offender causing 
vulnerabilities in 80\% of the images. Packages like util-linux, shadow, perl etc. 
also appear in each category of vulnerability. So, authors suggested that if 
these packages are targeted specifically then security of docker hub ecosystem 
can be improved.

In 2018, Martin et al. in~\cite{martin2018docker} performed a
vulnerability-oriented analysis of the Docker ecosystem.

In 2019, Zerouali et al. studied that
outdated packages lead to bugs and severity vulnerabilities in Docker
images~\cite{zerouali2019relation}.

In 2019, Sultan et al. in~\cite{sultan2019container} did a comprehensive
survey on container's security and identified main security threats
due to containers, images, registeries, orchestration, and host OS.
Primarily, this study proposed four use cases to explain security
requirements within the host-container level.
These use cases include: 

(1) Protecting container from applications inside it
(2) protecting one container from another container (3) protecting the host
from containers (4) protecting the container from the malicious host 

%Previous studies evaluated
%the security of Docker engine ~\cite{martin2018docker, sultan2019container, combe2016docker, bui2015analysis}.
%Other work studied security vulnerabilities in Docker images. 
%
%Shu et al. show that both official and community images
%contain more than 180 vulnerabilities on an average~\cite{Shu2017}.
%
%Zerouali et al. studied that
%outdated packages lead to bugs and severity vulnerabilities in Docker
%images~\cite{zerouali2019relation}.


\section{Conclusion}

In this chapter, we examine various security threats that
containers are prone to. We focus our investigation on the
security of Docker and Singularity containers because of their popularity.
In that context, we study a list of security requirements that every OS-level
virtualization should fulfill. Later, we investigate security of Docker and Singularity
containers based on these requirements. We broadly categories security of
containers into two types: internal security provided by containers, and
external security provided by the Linux kernel.
Internal security includes process isolation, device isolation, IPC
isolation, network isolation, limiting of resources in containers, and
vulnerabilities in images.
We then highlight solutions
provided by containers to provide internal security, and later,
we discuss how efficient these solutions are.
Further, we discuss external security, which is security provided by
the Linux kernel, to protect the host from containers, or containers from
containers. External security includes Linux
capabilities and LSM framework. Linux capabilities can be
disabled/enabled as needed, and LSM framework is used
to define various security profiles for containers.
Inspite of all these efforts, it is clear that there is
still a need of security enhancement in containers.
